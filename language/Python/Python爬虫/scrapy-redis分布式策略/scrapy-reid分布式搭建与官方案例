##################################
分布式目前并不是一定要学，时间久了，可能忘了，所以暂时不学了
#####################################

搭建Redis-Scrapy框架分布式爬虫
Scrapy是一个普通的爬虫框架，但是不支持分布式，scrapy-redis是为了更方便的实现scrapy分布式爬取，而提供了一些以redis为基础的组件
scrapy-redis提供了下面四种组件(四种组件意味着这四个模块要做相应的修改):
Schedule 队列，先进先出，存到redis中
Duplication Filter # 去重操作，但是scrapy是基于内存的，所以一终止就清空内存，下次从头运行，但是scrapy-redis框架不会，直接从redis数据库中取值，会从上次中断的地方开始
Item pipeline
Base Spider

所有的爬虫段共享一个数据库
请求队列，请求指纹和爬取数据都存到redis数据库中

Master端(核心服务器): 搭建一个Redis数据库，不负责爬取，只负责url指纹判重、Request的分配，以及数据的存储
Slaver端(爬虫程序执行端): 使用其他机器搭建，负责执行爬虫程序，运行过程中提交新的Request给Master
1.首先slaver端从Master端拿任务(Request、url)进行数据抓取，Slaver抓取数据的同时，产生新任务的Request便提交给Master
2.Master端只有一个Redis数据库，负责将未处理的Request去重和任务分配，将处理后的Request加入待爬队列，并且存储爬取的数据

缺点： Scrapy-Redis调度的任务是Request对象，里面信息量比较大(不仅包含url，还有callback函数，headers等信息)，可能导致的结果就是降低爬虫的速度、
而且会占用Redis大量的存储空间，所有要保证效率，需要一定的硬件水平。
Redis对带宽也是有要求的，局域网中搭建分布式也是不合适的，因为带宽一定，只要在不同网段内搭建分布式才是比较好的

##################################
有一个很完整的有缘网的案例，以后用到这块可以仔细看下，现在就不看了




















